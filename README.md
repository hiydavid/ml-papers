# ML Papers

## To-Read
* Five Years of GPT Progress [[Link]](https://finbarr.ca/five-years-of-gpt-progress/)
* Sparks of Artificial General Intelligence: Early Experiments with GPT-4 [[Link]](https://arxiv.org/pdf/2303.12712.pdf)
* Imbalanced Classification via Explicit Gradient Learning From Augmented Data [[Link]](https://arxiv.org/abs/2202.10550)
* Estimating Treatment Effects with Causal Forests: An Application [[Link]](https://arxiv.org/abs/1902.07409)
* TabNet: Attentive Interpretable Tabular Learning [[Link]](https://arxiv.org/abs/1908.07442)
* TabTransformer: Tabular Data Modeling Using Contextual Embeddings [[Link]](https://arxiv.org/abs/2012.06678)
* Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations [[Link]](https://arxiv.org/abs/1905.07697)
* On Embeddings for Numerical Features in Tabular Deep Learning [[Link]](https://arxiv.org/abs/2203.05556)
* Time2Vec: Learning a Vector Representation of Time [[Link]](https://arxiv.org/abs/1907.05321)
* TabDDPM: Modelling Tabular Data with Diffusion Models [[Link]](https://arxiv.org/abs/2209.15421)

## Read
### Machine Learning General
* Machine Learning and Causality: The Impact of Financial Crises on Growth [[Link]](shorturl.at/izFMR)
* A Comparative Study of Hyper-Parameter Optimization Tools [[Link]](https://arxiv.org/abs/2201.06433)
* WeightedSHAP: analyzing and improving Shapley based feature attributions [[Link]](https://arxiv.org/abs/2209.13429)
* Machine Learning Operations (MLOps): Overview, Definition, and Architecture [[Link]](https://arxiv.org/abs/2205.02302)
* Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift [[Link]](https://arxiv.org/abs/1502.03167)
* Deep Residual Learning for Image Recognition [[Link]](https://arxiv.org/abs/1512.03385)
* A Unified Approach to Interpreting Model Predictions [[Link]](https://arxiv.org/abs/1705.07874)
* Focal Loss for Dense Object Detection [[Link]](https://arxiv.org/abs/1708.02002)
* Cyclical Learning Rates for Training Neural Networks [[Link]](https://arxiv.org/abs/1506.01186)
* Entity Embeddings of Categorical Variables [[Link]](https://arxiv.org/abs/1604.06737)
* Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning [[Link]](https://arxiv.org/abs/1609.06570)

### Business Problem Domains
* Survival Regression with Accelerated Failure Time Model in XGBoost [[Link]](https://arxiv.org/abs/2006.04920)
* Random Survival Forests [[link]](https://arxiv.org/abs/0811.1645)
* Understanding Survival Analysis: Kaplan-Meier Estiamte [[Link]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059453/)
* Predicting Customer Lifetime Values: E-Commerce Use Case [[Link]](https://arxiv.org/abs/2102.05771)
* A Deep Probabilistic Model for Customer Lifetime Value Prediction [[Link]](https://arxiv.org/abs/1912.07753)
* Predicting Customer Churn: Extreme Gradient Boosting with Temporal Data [[Link]](https://arxiv.org/abs/1802.03396)
* Behavioral Modeling for Churn Prediction [[Link]](https://arxiv.org/abs/1512.06430)
* Deep & Cross Network for Ad Click Predictions [[Link]](https://arxiv.org/abs/1708.05123)
* Abuse and Fraud Detection in Streaming Services Using Heuristic-Aware Machine Learning [[Link]](https://arxiv.org/abs/2203.02124)

### Graph Neural Networks
* Temporal Graph Networks for Deep Learning on Dynamic Graphs [[Link]](https://arxiv.org/abs/2006.10637)
* A Review on Graph Neural Network Methods in Financial Applications [[Link]](https://arxiv.org/abs/2111.15367)
* A Survey on Graph Representation Learning Methods[[Link]](https://arxiv.org/abs/2204.01855v2)

### Representation Learning
* User Profiling through Deep Multimodal Fusion [[Link]](https://faculty.washington.edu/mdecock/papers/gfarnadi2018a.pdf)
* DAC: Deep Autoencoder-based Clustering [[Link]](https://arxiv.org/abs/2102.07472)
* Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks [[Link]](https://cs.stanford.edu/~srijan/pubs/jodie-kdd2019.pdf)

### Tabular Data
* PyTorch Tabular: A Framework for Deep Learning with Tabular Data [[Link]](https://arxiv.org/abs/2104.13638)
* Why Do Tree-Based Models Still Outperform Deep Learning on Tabular Data [[Link]](https://arxiv.org/abs/2207.08815)
* An Embedding Learning Framework for Numerical Features in CTR Prediction [[Link]](https://arxiv.org/abs/2012.08986)
* DCN V2: Improved Deep & Cross Network and Practical Lessons [[Link]](https://arxiv.org/abs/2008.13535)
* Revisiting Deep Learning Models for Tabular Data [[Link]](https://arxiv.org/abs/2106.11959)
* Tabular Data: Deep Learning is Not All You Need [[Link]](https://arxiv.org/abs/2106.03253?source=mlcontests)
* Deep Neural Networks and Tabular Data: A Survey [[Link]](https://arxiv.org/abs/2110.01889)
* XGBoost: A Scalable Tree Boosting System [[Link]](https://arxiv.org/abs/1603.02754)

### Time Series
* Churn Prediction with Sequential Data and Deep Neural Networks [[Link]](https://arxiv.org/abs/1909.11114)
* Forecasting with Trees [[Link]](https://www.sciencedirect.com/science/article/pii/S0169207021001679)
* Deep Learning for Time Series Forecasting: Tutorial and Literature Survey [[Link]](https://arxiv.org/abs/2004.10240)
* DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks [[Link]](https://arxiv.org/abs/1704.04110)
* NeuralProphet: Explainable Forecasting at Scale [[Link]](https://arxiv.org/abs/2111.15397)
* Prophet: Forecasting at Scale [[Link]](https://peerj.com/preprints/3190.pdf)
* AR-Net: A simple Auto-Regressive Neural Network for time-series [[Link]](https://arxiv.org/abs/1911.12436)
* Conditional Time Series Forecasting with Convolutional Neural Networks [[Link]](https://arxiv.org/abs/1703.04691)
* WaveNet: A Generative Model for Raw Audio [[Link]](https://arxiv.org/abs/1609.03499)
* An Experimental Review on Deep Learning Architectures for Time Series Forecasting [[Link]](https://arxiv.org/abs/2103.12057)
* Do We Really Need Deep Learning Models for Time Series Forecasting? [[Link]](https://arxiv.org/abs/2101.02118)
* Machine Learning vs Statistical Methods for Time Series Forecasting: Size Matters [[Link]](https://arxiv.org/abs/1909.13316)

### Blogposts / Presentations
* XGBSE: Improving XGBoost for Survival Analysis [[Link]](https://towardsdatascience.com/xgbse-improving-xgboost-for-survival-analysis-393d47f1384a)
* An Overview of Gradient Descent Optimization Algorithms [[Link]](https://ruder.io/optimizing-gradient-descent/)
* An Updated Overview of Gradient Descent Optimization Algorithms [[Link]](https://johnchenresearch.github.io/demon/)
* A Recipe for Training Neural Networks[[Link]](https://karpathy.github.io/2019/04/25/recipe/)
* Deep Neural Nets: 33 Years Ago and 33 Years From Now [[Link]](https://karpathy.github.io/2022/03/14/lecun1989/)
* The Spelled-Out Intro to Neural Networks and Backpropagation: Building Micrograd [[Link]](https://youtu.be/VMj-3S1tku0)
* The Spelled-Out Intro to Language Modeling: Pt.1 MakeMore with Bigrams [[Link]](https://youtu.be/PaCmpygFfXo)
* The Spelled-Out Intro to Language Modeling: Pt.2 MakeMore with MLP [[Link]](https://youtu.be/TCH_1BHY58I)
* The Spelled-Out Intro to Language Modeling: Pt.3 Activation, Gradients, BatchNorm [[Link]](https://youtu.be/P6sfmUTpUmc)
* The Spelled-Out Intro to Language Modeling: Pt.4 Becoming a Backprop Ninja [[Link]](https://youtu.be/q8SA3rM6ckI)
* The Spelled-Out Intro to Language Modeling: Pt.5 WaveNet [[Link]](https://youtu.be/t3YJ5hKiMQ0)
* Let's Build GPT: From Scratch, In Code, Spelled Out [[Link]](https://youtu.be/kCc8FmEb1nY)
