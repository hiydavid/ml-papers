# ML Papers

## To-Read
* Revisiting Pretraining Objectivew for Tabular Deep Learning [[Link]](https://arxiv.org/abs/2207.03208)
* Forecasting with Tress [[Link]](https://www.sciencedirect.com/science/article/pii/S0169207021001679)
* Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations [[Link]](https://arxiv.org/abs/1905.07697)
* On Embeddings for Numerical Features in Tabular Deep Learning [[Link]](https://arxiv.org/abs/2203.05556)
* Monolith: Real Time Recommendation System with Collisionless Embedding Table [[Link]](https://arxiv.org/abs/2209.07663)
* A Comparative Study of Hyper-Parameter Optimization Tools [[Link]](https://arxiv.org/abs/2201.06433)
* Churn Prediction with Sequential Data and Deep Neural Networks [[Link]](https://arxiv.org/abs/1909.11114)
* Time2Vec: Learning a Vector Representation of Time [[Link]](https://arxiv.org/abs/1907.05321)
* TabDDPM: Modelling Tabular Data with Diffusion Models [[Link]](https://arxiv.org/abs/2209.15421)
* DeepGBM: A Deep Learning Framework Distilled by GBDT [[Link]](https://www.microsoft.com/en-us/research/uploads/prod/2019/08/deepgbm_kdd2019__CR_.pdf)
* Cyclical Focal Loss [[Link]](https://arxiv.org/abs/2202.08978)
* Forecast Evaluation for Data Scientists: Common Pitfalls and Best Practices [[Link]](https://arxiv.org/abs/2203.10716)
* On the Measure of Intelligence [[Link]](https://arxiv.org/abs/1911.01547)

## Read
### Machine Learning General
* Abuse and Fraud Detection in Streaming Services Using Heuristic-Aware Machine Learning [[Link]](https://arxiv.org/abs/2203.02124)
* WeightedSHAP: analyzing and improving Shapley based feature attributions [[Link]](https://arxiv.org/abs/2209.13429)
* Machine Learning Operations (MLOps): Overview, Definition, and Architecture [[Link]](https://arxiv.org/abs/2205.02302)
* Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift [[Link]](https://arxiv.org/abs/1502.03167)
* Deep Residual Learning for Image Recognition [[Link]](https://arxiv.org/abs/1512.03385)
* A Unified Approach to Interpreting Model Predictions [[Link]](https://arxiv.org/abs/1705.07874)
* Focal Loss for Dense Object Detection [[Link]](https://arxiv.org/abs/1708.02002)
* Cyclical Learning Rates for Training Neural Networks [[Link]](https://arxiv.org/abs/1506.01186)
* Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning [[Link]](https://arxiv.org/abs/1609.06570)

### Graph Neural Networks
* Temporal Graph Networks for Deep Learning on Dynamic Graphs [[Link]](https://arxiv.org/abs/2006.10637)
* A Review on Graph Neural Network Methods in Financial Applications [[Link]](https://arxiv.org/abs/2111.15367)
* A Survey on Graph Representation Learning Methods[[Link]](https://arxiv.org/abs/2204.01855v2)

### Representation Learning
* User Profiling through Deep Multimodal Fusion [[Link]](https://faculty.washington.edu/mdecock/papers/gfarnadi2018a.pdf)
* DAC: Deep Autoencoder-based Clustering [[Link]](https://arxiv.org/abs/2102.07472)
* Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks [[Link]](https://cs.stanford.edu/~srijan/pubs/jodie-kdd2019.pdf)

### Tabular Data
* PyTorch Tabular: A Framework for Deep Learning with Tabular Data [[Link]](https://arxiv.org/abs/2104.13638)
* Why Do Tree-Based Models Still Outperform Deep Learning on Tabular Data [[Link]](https://arxiv.org/abs/2207.08815)
* An Embedding Learning Framework for Numerical Features in CTR Prediction [[Link]](https://arxiv.org/abs/2012.08986)
* DCN V2: Improved Deep & Cross Network and Practical Lessons [[Link]](https://arxiv.org/abs/2008.13535)
* Deep & Cross Network for Ad Click Predictions [[Link]](https://arxiv.org/abs/1708.05123)
* Predicting Customer Churn: Extreme Gradient Boosting with Temporal Data [[Link]](https://arxiv.org/abs/1802.03396)
* Behavioral Modeling for Churn Prediction [[Link]](https://arxiv.org/abs/1512.06430)
* Revisiting Deep Learning Models for Tabular Data [[Link]](https://arxiv.org/abs/2106.11959)
* Tabular Data: Deep Learning is Not All You Need [[Link]](https://arxiv.org/abs/2106.03253?source=mlcontests)
* Deep Neural Networks and Tabular Data: A Survey [[Link]](https://arxiv.org/abs/2110.01889)
* XGBoost: A Scalable Tree Boosting System [[Link]](https://arxiv.org/abs/1603.02754)

### Time Series
* Deep Learning for Time Series Forecasting: Tutorial and Literature Survey [[Link]](https://arxiv.org/abs/2004.10240)
* DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks [[Link]](https://arxiv.org/abs/1704.04110)
* NeuralProphet: Explainable Forecasting at Scale [[Link]](https://arxiv.org/abs/2111.15397)
* Prophet: Forecasting at Scale [[Link]](https://peerj.com/preprints/3190.pdf)
* AR-Net: A simple Auto-Regressive Neural Network for time-series [[Link]](https://arxiv.org/abs/1911.12436)
* Conditional Time Series Forecasting with Convolutional Neural Networks [[Link]](https://arxiv.org/abs/1703.04691)
* WaveNet: A Generative Model for Raw Audio [[Link]](https://arxiv.org/abs/1609.03499)
* An Experimental Review on Deep Learning Architectures for Time Series Forecasting [[Link]](https://arxiv.org/abs/2103.12057)
* Do We Really Need Deep Learning Models for Time Series Forecasting? [[Link]](https://arxiv.org/abs/2101.02118)
* Machine Learning vs Statistical Methods for Time Series Forecasting: Size Matters [[Link]](https://arxiv.org/abs/1909.13316)

### Blogposts / Presentations
* An Overview of Gradient Descent Optimization Algorithms [[Link]](https://ruder.io/optimizing-gradient-descent/)
* An Updated Overview of Gradient Descent Optimization Algorithms [[Link]](https://johnchenresearch.github.io/demon/)
* A Recipe for Training Neural Networks[[Link]](https://karpathy.github.io/2019/04/25/recipe/)
* Deep Neural Nets: 33 Years Ago and 33 Years From Now [[Link]](https://karpathy.github.io/2022/03/14/lecun1989/)
* The Spelled-Out Intro to Neural Networks and Backpropagation: Building Micrograd [[Link]](https://youtu.be/VMj-3S1tku0)
* The Spelled-Out Intro to Language Modeling: Pt.1 MakeMore with Bigrams [[Link]](https://youtu.be/PaCmpygFfXo)
* The Spelled-Out Intro to Language Modeling: Pt.2 MakeMore with MLP [[Link]](https://youtu.be/TCH_1BHY58I)
* The Spelled-Out Intro to Language Modeling: Pt.3 Activation, Gradients, BatchNorm [[Link]](https://youtu.be/P6sfmUTpUmc)
* The Spelled-Out Intro to Language Modeling: Pt.4 Becoming a Backprop Ninja [[Link]](https://youtu.be/q8SA3rM6ckI)
* The Spelled-Out Intro to Language Modeling: Pt.5 WaveNet [[Link]](https://youtu.be/t3YJ5hKiMQ0)
